<!DOCTYPE html>
<html>
  <head>
    <style type="text/css">
@import url('https://fonts.googleapis.com/css?family=Dosis');

body {
    color: white;
    font-family: Verdana, Geneva, Tahoma, sans-serif;
}

a, a:hover, a:visited, a:active {
    color: lightblue;
}

.remark-slide-number {
    visibility: hidden;
}

.remark-slide-content {
    background-color: #282828;
}

.remark-slide-content h1 {
    font-size: 1.7em;
    margin-bottom: 0.5em;
}

.remark-slide-content h2 {
    font-size: 1.4em;
    margin-bottom: 0.2em;
}

.remark-slide-content table {
    border-collapse: collapse;
}

.remark-slide-content table td, .remark-slide-content table th {
    border: 1px solid black;
    padding: 0.5em;
}

    </style>
  </head>
  <body>
     <textarea id="source">
class: center, middle

# Libp2p - zkSummit

## Power to the peers

<div style="position: absolute; bottom: 5%; left: 0; right: 0;">
    <div style="text-align: center">
        <img src="parity-logo.png" alt="Parity" height="128" />
    </div>
</div>
<div style="position: absolute; bottom: 5%; left: 5%;">
.left[
    <img src="twitter.png" alt="Twitter" height="16" /> twitter.com/tomaka17<br />
    <img src="github.png" alt="GitHub" height="16" /> github.com/tomaka<br />
]
</div>
<div style="position: absolute; bottom: 5%; right: 5%;">
.right[
    github.com/Vurich <img src="github.png" alt="GitHub" height="16" /><br />
]
</div>
---

# What is libp2p?

- Peer-to-peer networking protocol
- Implementations in Go, JavaScript and Rust (us!)
- Used by IPFS
- Will be used by Polkadot and Parity
- Possibly by Ethereum in the future (discussions are open)

<div style="position: absolute; bottom: 5%; left: 5%;">
.left[
    <img src="ipfs.png" alt="IPFS" height="64" />
]
</div>
<div style="position: absolute; bottom: 5%; left: 0; right: 0;">
    <div style="text-align: center">
        <img src="polkadot.png" alt="Polkadot" height="64" />
    </div>
</div>
<div style="position: absolute; bottom: 5%; right: 5%;">
.right[
    <img src="parity-logo.png" alt="Parity" height="64" />
]
</div>
---

# Why libp2p?

- Most existing peer-to-peer networking solutions enforce use of direct
  connections over TCP-IP
- Supporting additional transports requires a huge overhaul of the protocol and
  significant development work
- libp2p attempts to fix this by being pluggable from the very start

???

- (after second point): this means that, for example, a node running in a
  browser cannot connect to a node running in the cloud, or that proxying
  support must be baked into the protocol itself

---

# Multiaddress

In traditional peer-to-peer systems, a node is contacted through an IP address,
a TCP port and an UDP port.

In libp2p, a node is contacted through a *multiaddress*. This specifies which
transports and which protocols to use.

Examples:

- `/ip4/80.129.4.75/tcp/8200`
- `/ip4/80.129.4.75/tcp/8200/ws`
- `/ip6/2001:db8:a0b:12f0::1/tcp/3050`
- `/onion/timaq4ygg2iegci7:80/http`
- `/dns/example.com/tcp/5000`
- `/ip4/125.90.85.23/tcp/5000/p2p-circuit/ip4/90.2.98.122/tcp/9001`

libp2p nodes can communicate with each other through TCP/IP, WebSockets, unix
pipes, and much more.

???

- `/ip4/80.129.4.75/tcp/8200` (TCP/IPv4)
- `/ip4/80.129.4.75/tcp/8200/ws` (websockets)
- `/ip6/2001:db8:a0b:12f0::1/tcp/3050` (TCP/IPv6)
- `/onion/timaq4ygg2iegci7:80/http` (Onion routing/Tor network)
- `/dns/example.com/tcp/5000` (DNS)
- `/ip4/125.90.85.23/tcp/5000/p2p-circuit/ip4/90.2.98.122/tcp/9001` (TCP/IPv4
  with a proxy that is contacted using TCP/IPv4)

- Websockets means that we can run a JavaScript or WASM libp2p node inside a
  browser
- Restriction: must be able to transport a continuous stream of bytes (only to
  make writing protocol implementations for libp2p easier, and could be lifted
  in the future)
- Restriction rules out UDP without some layer over the top that adds in-order
  reliable messaging to UDP like UDT.

---

# Protocol negotiation

Once a connection between two nodes is established, the dialer negotiates with
the listener a protocol to apply to the connection.

Example communications between two nodes:

<img src="multistream-select.png" alt="" />

???

In this example, we negotiate the protocol `/plaintext/1.0.0`, then the protocol
`/mplex/6.7.0`.

---

# Encryption layer

The first protocol negotiated when a connection is open is the security layer.

Right now, two protocols exist:
- *plaintext*
- *secio*

We probably don't need more any time soon, *secio* is very flexible.

???

- *plaintext*, a basic pass-through protocol. Useful for debugging.
- *secio*, that provides full end-to-end encryption.
- This is roughly analogous to HTTP vs HTTPS - the data transferred is the same,
  but in one the data is encrypted.
- In *secio*, the cipher, hash function, and key exchange algorithm are not
  hardcoded in the protocol, and are also negotiated between the two nodes
  during the *secio* handshake. This means we can incrementally upgrade nodes if
  the existing hash function is found to be lacking.

---

# Multiplexing

On top of the security layer, the second protocol that is negotiated is the
multiplexing layer.

Three protocols exist:
- *yamux*
- *spdy*
- *mplex*

<div style="text-align:center">
    <img src="multiplexing.svg" alt="" />
</div>

???

- *yamux*, only implemented in Go
- *spdy*, only implemented in JavaScript (actually implemented in a few
  languages but only JS has it available as a libp2p multiplexing solution)
  - Google's multiplexing solution that is the basis for how HTTP/2 implements
    multiplexing
- *mplex*, implemented in Go, JavaScript and now Rust
  - Originally written as an ad-hoc spec in JavaScript but is now de-facto
    standardised due to its reimplementation in JS and Rust.

Multiplexing allows both nodes to open multiple substreams on a single
connection, where each of these substreams uses a different protocol and is
treated as if it was separate connection. The extra overhead for these
substreams is minimal.

---

# Top-level protocols

In each multiplexed substream, a top-level protocol is negotiated.

Example of some protocols:

- *ping*
- *identify*
- *floodsub*
- *kademlia*
- etc.

Or you can also create your own protocol, which is often what you want.

Example:

- IPFS uses the *bitswap* protocol.
- Polkadot and Ethereum would also use their own custom protocol.

???

- *ping* - exactly what it says on the tin
- *identify* - a protocol allowing nodes to express a unique identity
- *floodsub* - multiple-producer, multiple-consumer decentralised message bus
- *kademlia* - decentralised peer discovery and record storage
- etc.

- IPFS uses the *bitswap* protocol (most of IPFS just leverages libp2p instead
  of requiring a custom implementation, this protocol just adds the concept of
  files on top).
- Mention that Parity intends to implement libp2p as a secondary communication
  mechanism to their existing TCP-only solution.

---

# Protocol detail: *identify*

Whenever a dialer connects to a listener, a listener responding to the
*identify* protocol responds with information about itself.

These information include:

- The public key of the node (useful if secio isn't used).
- The multiaddresses the node is listening on.
- The protocols the node supports.
- The version of libp2p the node implements.
- The top-level protocol that the node wants (eg. "ipfs", "polkadot")

???

**Note**: A common situation is that A dials B, then B opens a multiplexed
  substream to A and negotiates the *identify* protocol on it. It is then A that
  sends information about itself to B, allowing B to learn about A.

---

# Protocol detail: *floodsub*

Publish-subscribe protocol.

The *floodsub* protocol allows you to broadcast messages over the network.

Each message has a topic. Nodes subscribe to specific topics and will discard
messages that do not match any of the topics they are registered to.

Example usages:

- Messages in a chat application.
- Broadcasting new blocks in a blockchain.
- Moves in a turn-based strategy game.

Messages can be signed in order to prove the author.

???

What this means is that a node will send a message to all the nodes it knows
about, and then these nodes will send the message to all the nodes _they_ care
about, and so forth.

Signing is currently unimplemented in the Rust implementation of *floodsub*

---

# Protocol detail: kademlia

Kademlia is a Distributed Hash Table (DHT).

A DHT is similar to a traditional hash table, with each node acting like a
bucket, except the nodes can share elements whereas entries tend to belong to
precisely one hash table bucket.

Each node that supports kademlia manages two DHTs: one for peers, and one for
data.

When a node joins the network, it notifies the nodes it connects to in order to
get inserted in the peers' hash table. If we choose a list of "bootstrap" nodes
that are known about before connecting to the network, we can use these to
incrementally discover every node on the network.

???

The entries that a node stores are determined based on
its public key. This ensures a relatively-good distribution of entries without
central coordination.

The data records are totally arbitrary and can have basically any key and any
value. Similarly to a K/V store like Redis, records in both the peer and data
stores expire after some amount of time.

These bootstrap nodes do not need to be special, or owned by the libp2p
developers. They simply need to be nodes that are already connected to the
network and whose addresses are already known.

---

# Why Rust?

- Efficient but readable.
- Control over resources and resource use.
- Can write bindings into Rust from other languages.
- Strict types and strict ownership system.

???

- Allows us to write code that is as readable and maintainable as code in
  any modern language but is as efficient as a hand-rolled C implementation.
- We can get fine-grained control over resource use. This is useful, as a
  peer-to-peer system is more vulnerable to resource exhaustion attacks than
  in a client-server model.
- Rust can easily be called into from other languages in a way that is
  impossible or impractical in languages like Go and JavaScript.
- Rust's strict type system and ownership model means that we can get a better
  understanding of the structure of libp2p itself, making it easier to port to
  other languages like Haskell which may be stricter than Go and JavaScript.

---

# Designing a small chat application

Let's write a small peer-to-peer application that allows all the members of the
network to chat together.

How it all plugs together:

- When they start, nodes have absolutely no idea how to access other nodes. In
  order to be able to function, we need to have a list of *bootstrap nodes*.
- When a node starts, it generates a key pair for itself or loads an existing
  key pair from the disk.
- It then uses the Kademlia protocol in order to discover nodes whose IDs are
  near its own key pair. This process involves connecting to some of the
  boostrap nodes, opening the Kademlia protocol.
- It will then connect to a certain number of closest nodes and open the
  *floodsub* protocol.
- Any message received from any of these nodes through *floodsub* will be
  printed to stdout. Anything received by stdin will be broadcasted as a message
  to all the network connected through *floodsub*.

---
class: center, middle

# Walkthrough with rust-libp2p

Let's build this chat application with rust-libp2p.

https://github.com/libp2p/rust-libp2p

**Warning**: the code below doesn't exactly match the current API because the
library is still in development.

Demo code can be found here: TODO

---

# Walkthrough #1: Initialization

```rust
let bootstrap_peer_id = BOOTSTRAP_ID;

// This creates a peerstore in-process
let peer_store = Arc::new(MemoryPeerstore::empty());

// The `is_bootstrap` flag would probably be passed on the command line
if !is_bootstrap {
// Add bootstrap node to peer store
    peer_store
        .peer_or_create(&bootstrap_peer_id)
        .add_addr("/ip4/127.0.0.1/tcp/10101".parse().unwrap(),
                Duration::from_secs(3600 * 24 * 365));
}

let my_peer_id = if is_bootstrap {
    // Hardcoded peer ID
    bootstrap_peer_id
} else {
    // Otherwise, we generate a key
    let key = (0..2048).map(|_| rand::random::<u8>())
                       .collect::<Vec<_>>();
    PeerId::from_public_key(&key)
};
```

???

Nodes have two modes: bootstrap, or not.

We create what is called a *peerstore*, and store the bootstrap node in it
(unless we are the bootstrap node). The *peerstore* is a database of node
information.

For the bootstrap node's ID we'd just use some hardcoded value. The only thing
that matters is that it's unique and that all nodes agree on its value.

We use an in-process peerstore (i.e. it's not stored on disk and will be
destroyed when the process quits)

This adds the bootstrap node's ID to the peer store with a hardcoded IP address.
We only have a single bootstrap node for this demo but in a real application
you'd have many, so that if one or more bootstrap nodes go down then you can
still connect to the network.

If we're the bootstrap node then our peer ID is a hardcoded value (since we only
have one bootstrap node then this is simple)

We generate a key using `/dev/urandom`.

---

# Walkthrough #2: Build the transport

This is the core of the configuration of libp2p.

We configure low-level transports, add dummy encryption, and configure
*identify* on top.

The Rust code to do this looks like this:

```rust
let mut core = tokio_core::reactor::Core::new().unwrap();

let without_identify =
    // `Ws` first, `Tcp` if that fails.
    WsConfig::new(TcpConfig::new(core.handle())).or_transport(TcpConfig::new(core.handle()))
        // Plain-text "encryption".
        .with_upgrade(PlainTextConfig)
        // Multiplexing
        .with_upgrade(BufferedMplexConfig::<[_; 256]>::new()).into_connection_reuse();

let transport = IdentifyTransport::new(without_identify, peer_store.clone());
```

???

`core` allows us to run libp2p asynchronously.

This is the core of the configuration of libp2p. Essentially, it defines the
configuration of protocols that libp2p supports. We want to be able to use the
regular internet (TCP/IP) _or_ websockets-over-TCP/IP to transfer our data, and
we want to allow multiplexing (so for each stream provided by either TCP/IP or
websockets, we can send many streams of data). We don't care about encrypting
our messages so we use the *plaintext* dummy encryption protocol.

Lastly, we add *identify* on top. This means that nodes are automatically
identified when we connect to them and their node IDs determined and stored in
the `peer_store`.

---

# Walkthrough #3: prepare the configuration for the top-level protocols

We prepare the configuration for the top-level protocols that the server will
handle: *identify*, *kademlia* and *floodsub*.

```rust
// We create the configuration for *floodsub*
let (floodsub, fs_rx) = FloodSubUpgrade::new(my_peer_id.clone());

// Configure *kademlia*
let kad_cfg = KademliaConfig {
    parallelism: 3,
    peer_store: peer_store,
    local_peer_id: my_peer_id.clone(),
    timeout: Duration::from_secs(2),
};
let kad_ctl_proto = KademliaControllerPrototype::new(kad_cfg);
let kad_upgrade = KademliaUpgrade::from_prototype(&kad_ctl_proto);

// Combine the three protocols
let protocols_configuration = ConnectionUpgrader {
    kad: kad_upgrade,
    identify: libp2p_identify::IdentifyProtocolConfig,
    floodsub: floodsub.clone(),
};
```

???

We create the configuration for *kademlia* (plus the controller that allows us
to send commands and receive data from the network).

Finally, we create an instance of a custom struct that allows us to implement
all three top-level protocols simultaneously.

---

# Walkthrough #4: build the swarm

```rust
let (swarm_controller, swarm_future) = libp2p_swarm::swarm(
    transport, protocols_configuration, |upgrade, client_addr| {
        match upgrade {
            // *kademlia*
            Protocol::Kad(kad) => Box::new(kad) as Box<_>,
            // *floodsub*
            Protocol::FloodSub(future) => {
                Box::new(future) as Box<_>
            },
            // *identify*
            Protocol::Identify(id) => {
                match id {
                    IdentifyOutput::Sender { sender, .. }) => {
                        sender.send(build_local_identify_info(),
                                    &client_addr)
                    },
                    IdentifyOutput::RemoteInfo { .. } => {
                        unreachable!()
                    },
                }
            }
        }
    },
);
```

???

We now create what is called a *swarm*. This is the object that will manage all
the active connections. It's the central engine by which everything in libp2p is
driven.

Our custom struct produces an enum. If you don't know Rust, all you need to know
is that we can handle values from each of *kademlia*, *floodsub* and *identify*
seperately. If we only used one top-level protocol then we would only receive
the values from that protocol, our custom struct simply gathers up all the
values from all the protocols and turns it into a single value.

---

# Walkthrough #5: start listening

We ask the `swarm_controller` to start listening for incoming connections.

```rust
let addr: Multiaddr = if is_bootstrap {
    // Hardcoded port
    "/ip4/0.0.0.0/tcp/10101".parse().unwrap()
} else {
    // Let OS choose port
    "/ip4/0.0.0.0/tcp/0".parse().unwrap()
};

let actual_addr = swarm_controller.listen_on(addr.clone())
    .expect("failed to listen to multiaddress");
info!("Now listening on {}", actual_addr);
```

???

If we're the bootstrap node, we start listening on a hardcoded port so that
other nodes can find us. For now we only listen on TCP/IP but we could listen on
multiple protocols if we wanted to.

We pass this address into the swarm controller, which then returns the "real"
address. This replaces the IP address with our real IP address and the port with
our real port.

---

# Walkthrough #6: subscribe to a floodsub topic

Having a swarm controller makes it possible to perform actions on the network by
sending commands to the top-level protocols. 

```rust
let topic = TopicBuilder::new("chat").build();

// Create controller for *floodsub*
let floodsub_ctl = FloodSubController::new(
    &floodsub_upgrade,
    swarm_controller.clone(),
);

floodsub_ctl.subscribe(&topic);
```

???

Here, we create a controller that sends messages to *floodsub* and use it to ask
*floodsub* to subscribe to a topic. This will tell everyone we are connected to
and will connect to that we want to receive messages for this topic. For now
we're not connected to anyone, but when we do we'll communicate our topics to
them.

---

# Walkthrough #7: perform a Kademlia node find

We use the `swarm_controller` to perform a Kademlia node find, and connect to all the nodes that
are closest to ours.

```rust
// Create controller for *kademlia*
let (kad_controller, kad_init) =
    kad_ctl_proto.start(swarm_controller.clone());

let finished_enum = kad_controller
    // Ask for closest nodes
    .find_node(my_peer_id.clone())
    .and_then(move |out| {
        let local_hash = U512::from(my_peer_id.hash());

        // Dial to the nodes
        for n in out {
            let addr = AddrComponent::P2P(n.into_bytes()).into();

            // Ignore errors
            let _ = swarm_controller.dial_to_handler(
                addr,
                floodsub_upgrade.clone(),
            );
        }

        Ok(())
    });
```

???

We ask *kademlia* for the nodes closest to us. Then we take these nodes and dial
each of them in turn, requesting the "p2p" protocol. We ignore errors since it's
just a demo.

---

# Walkthrough #8: sending and receiving messages

Whenever a message arrives on stdin, we dispatch it:

```rust
let stdin = spawn_stdin_stream_unbounded()
    .for_each(move |msg| {
        floodsub_ctl.publish(&topic, msg.into_bytes());
        Ok(())
    });
```

Whenever a message is received through floodsub, we write it to stdout:

```rust
let floodsub_rx = floodsub_rx.for_each(|msg| {
    // If the message is invalid UTF-8 we ignore it
    if let Ok(msg) = String::from_utf8(msg.data) {
        info!("< {}", msg);
    }
    Ok(())
});
```

???

This is different to the code in the demo repository because the demo code
handles line breaks properly. Essentially this sends each line from stdin to
*floodsub* and tells *floodsub* to send it out to the network.

---

# Walkthrough 9: group everything and run

`rust-libp2p` is fully asynchronous.

To run this code, we group it together and pass it into the `core`.

```rust
let final_future = swarm_future
    .select(floodsub_rx).discard()
    .select(stdin).discard()
    .select(finished_enum).discard()
    .select(kad_init).discard()

core.run(final_future).unwrap();
```

???

`rust-libp2p` is fully asynchronous. Everything we did so far just creates the
configuration, defining how we handle incoming connections and which protocols
we support initializations, and doesn't actually do anything. We now start
everything.

This is done by grouping everything into one future, and running it. This is
similar to the `select` keyword in Go - it creates a future that runs many
futures in parallel, ending when any of them end:

---

# Misc: running the same code in the browser

The same code can be compiled for asmjs or wasm and run in the browser.

A few adjustments are required:

- Building the set of available transports.
- Running the final future (see [this gist](http://bit.ly/2FZU3wQ) for an
  explanation and workaround).

Other than that, it's just:

```sh
cargo build --target=asmjs-unknown-emscripten
```

Or:

```sh
cargo build --target=wasm32-unknown-emscripten
```

???

- Building the set of available transports, as we cannot use TCP/IP (we just use
  websockets instead). This doesn't make a browser node incompatible with a
  desktop node, since they only need to share a single transport in order to
  communicate and the desktop nodes support websockets.
- Running the final future is more complicated because JavaScript doesn't have
  "true" threads (for the curious and Rust-savvy, you can see the linked gist
  for an explanation and a workaround).

---
class: center, middle

# Demo time?

Demo code can be found here: TODO

---
class: center, middle

# Thank you!

<div style="position: absolute; bottom: 5%; left: 0; right: 0;">
    <div style="text-align: center">
        <img src="parity-logo.png" alt="Parity" height="128" />
    </div>
</div>
<div style="position: absolute; bottom: 5%; left: 5%;">
.left[
    <img src="twitter.png" alt="Twitter" height="16" /> twitter.com/tomaka17<br />
    <img src="github.png" alt="GitHub" height="16" /> github.com/tomaka<br />
]
</div>
<div style="position: absolute; bottom: 5%; right: 5%;">
.right[
    github.com/Vurich <img src="github.png" alt="GitHub" height="16" /><br />
]
</div>
    </textarea>
     <script src="remark.min.js">
    </script>
    <script>
       var slideshow = remark.create();
    </script>
  </body>
</html>
